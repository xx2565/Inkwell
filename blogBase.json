{"singlePage": [], "startSite": "", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark", "urlMode": "pinyin", "script": "", "style": "", "head": "", "indexScript": "", "indexStyle": "", "bottomText": "", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 1, "allHead": "", "title": "Blog Title", "subTitle": "Blog description", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "postListJson": {"P1": {"htmlDir": "docs/post/gpu coding&arch.html", "labels": ["documentation"], "postTitle": "gpu coding&arch", "postUrl": "post/gpu%20coding%26arch.html", "postSourceUrl": "https://github.com/xx2565/Inkwell/issues/1", "commentNum": 0, "wordCount": 8874, "description": "# gemm\n```c++\n#include <cuda_runtime.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n# define BLOCKSIZE 16\n\n__global__ void gemm_kernel_tile(const float* __restrict__ a,\n                                  const float* __restrict__ b,\n                                  float* __restrict__ c,\n                                  int M, int N, int K){\n                                \n                                int y = blockIdx.y * blockDim.y + threadIdx.y;\n                                int x = blockIdx.x * blockDim.x + threadIdx.x;\n                                \n                                __shared__ float a_tile[BLOCKSIZE][BLOCKSIZE], b_tile[BLOCKSIZE][BLOCKSIZE];\n                                \n                                float sum = 0.0f;\n\n                                for(int i=0;i<K/BLOCKSIZE;++i){\n                                    // load to sahared memory a\n                                    int ax = threadIdx.x + i * BLOCKSIZE;\n                                    int ay = y;\n                                    if(ax < K && ay < M){\n                                        a_tile[threadIdx.y][threadIdx.x] = a[ay * K + ax];   // \u2b50\ufe0f \u9632\u6b62\u5171\u4eab\u5185\u5b58\u5750\u6807\u8d8a\u754c\n                                    }else{\n                                        a_tile[threadIdx.y][threadIdx.x] = 0.0f;\n                                    }\n                                    // load to sahared memory b\n                                    int bx = threadIdx.x;\n                                    int by = threadIdx.y + i * BLOCKSIZE;\n                                    if(bx < N && by < K){\n                                        b_tile[threadIdx.y][threadIdx.x] = b[by * N + bx];\n                                    }else{\n                                        b_tile[threadIdx.y][threadIdx.x] = 0.0f;\n                                    }\n\n                                    __syncthreads();  // \u2b50\ufe0f \u6570\u636e\u52a0\u8f7d\u5b8c\u6210\u4e4b\u540e\u540c\u6b65\n\n                                    \n                                    for(int i=0;i<BLOCKSIZE;++i){\n                                        sum += a_tile[threadIdx.y][i] * b_tile[i][threadIdx.x];\n                                    }\n                                    __syncthreads();  // \u2b50\ufe0f \u540c\u6b65\uff0c\u9632\u6b62\u63d0\u524d\u8fdb\u5165\u4e0b\u4e00\u8f6e\u8ba1\u7b97\u7136\u540e\u7d2f\u52a0\u9519\u8bef\n                                }\n                                if(x < N && y < M){\n                                    c[y * N + x] = sum;\n                                }\n                            }\n                                    \n\n\n__global__ void gemm_kernel(const float* __restrict__ a,\n                            const float* __restrict__ b,\n                            float* __restrict__ c,\n                            int M, int N, int K) {\n    // Each thread computes one element of C\n    int row = blockIdx.y * blockDim.y + threadIdx.y; // y -> row in C (0..M-1)\n    int col = blockIdx.x * blockDim.x + threadIdx.x; // x -> col in C (0..N-1)\n\n    if (row < M && col < N) {\n        float sum = 0.0f;\n        for (int k = 0; k < K; ++k) {\n            // A[row][k] * B[k][col]\n            sum += a[row * K + k] * b[k * N + col];\n        }\n        c[row * N + col] = sum;\n    }\n}\n\nint main() {\n    // Matrix dimensions: A(MxK) * B(KxN) = C(MxN)\n    const int M = 5000;\n    const int K = 6000;\n    const int N = 4000;\n\n    const size_t size_a = M * K * sizeof(float);\n    const size_t size_b = K * N * sizeof(float);\n    const size_t size_c = M * N * sizeof(float);\n\n    // Host memory allocation\n    float *h_a = (float*)malloc(size_a);\n    float *h_b = (float*)malloc(size_b);\n    float *h_c = (float*)malloc(size_c);\n    float *h_c_ref = (float*)malloc(size_c); // Optional: CPU reference\n\n    // Initialize host matrices\n    for (int i = 0; i < M * K; ++i) h_a[i] = 1.0f; // A all 1s\n    for (int i = 0; i < K * N; ++i) h_b[i] = 2.0f; // B all 2s\n    for (int i = 0; i < M * N; ++i) h_c[i] = 0.0f; // Initialize to 0\n\n    // Device memory allocation\n    float *d_a, *d_b, *d_c;\n    cudaError_t err;\n\n    err = cudaMalloc(&d_a, size_a);\n    if (err != cudaSuccess) { fprintf(stderr, 'cudaMalloc d_a failed: %s\\n', cudaGetErrorString(err)); return 1; }\n\n    err = cudaMalloc(&d_b, size_b);\n    if (err != cudaSuccess) { fprintf(stderr, 'cudaMalloc d_b failed: %s\\n', cudaGetErrorString(err)); return 1; }\n\n    err = cudaMalloc(&d_c, size_c);\n    if (err != cudaSuccess) { fprintf(stderr, 'cudaMalloc d_c failed: %s\\n', cudaGetErrorString(err)); return 1; }\n\n    // Copy data from host to device\n    cudaMemcpy(d_a, h_a, size_a, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_b, h_b, size_b, cudaMemcpyHostToDevice);\n    cudaMemcpy(d_c, h_c, size_c, cudaMemcpyHostToDevice);\n\n    // Kernel launch configuration\n    dim3 blockSize(16, 16); // 256 threads per block\n    dim3 gridSize((N + blockSize.x - 1) / blockSize.x,\n                  (M + blockSize.y - 1) / blockSize.y);\n\n    // Launch kernel\n    gemm_kernel_tile<<<gridSize, blockSize>>>(d_a, d_b, d_c, M, N, K);\n\n    // Check for kernel launch errors\n    err = cudaGetLastError();\n    if (err != cudaSuccess) {\n        fprintf(stderr, 'Kernel launch failed: %s\\n', cudaGetErrorString(err));\n        return 1;\n    }\n\n    // Wait for GPU to finish\n    cudaDeviceSynchronize();\n\n    // Copy result back to host\n    cudaMemcpy(h_c, d_c, size_c, cudaMemcpyDeviceToHost);\n\n    printf('First 10 elements of C (row 0, columns 0\uff5e9):\\n');\n    for (int i = 0; i < 10 && i < N; ++i) {\n        printf('C[0][%d] = %.2f\\n', i, h_c[i]);\n    }\n    printf('\\n');\n\n    // Optional: Verify result (C should be all 2*K = 400.0f)\n    bool correct = true;\n    float expected = 2.0f * K; // since A=1, B=2, sum over K terms: 1*2*K\n    for (int i = 0; i < M * N; ++i) {\n        if (abs(h_c[i] - expected) > 1e-5) {\n            correct = false;\n            break;\n        }\n    }\n\n    printf('Matrix multiplication result: %s\\n', correct ? 'PASSED' : 'FAILED');\n    if (!correct) {\n        printf('Example: h_c[0] = %f, expected = %f\\n', h_c[0], expected);\n    }\n\n    // Cleanup\n    free(h_a); free(h_b); free(h_c); free(h_c_ref);\n    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n    // no\n    return 0;\n}\n\n```\n\n# transpose\n```c++\n# include <stdio.h>\n# include <math.h>\n\n#define BLOCK_SIZE 32\n#define M 3000\n#define N 1000\n\n__managed__ int matrix[N][M];\n__managed__ int gpu_result[M][N];\n__managed__ int cpu_result[M][N];\n\n__global__ void gpu_matrix_transpose(int in[N][M], int out[M][N])\n{\n    int x = threadIdx.x + blockDim.x * blockIdx.x;\n    int y = threadIdx.y + blockDim.y * blockIdx.y;\n\n    if( x < M && y < N)\n    {\n        out[x][y] = in[y][x];\n    }\n}\n\n// \u521b\u5efam\u884c\uff0cn\u5217\u7684\u7ebf\u7a0b\u6570\u91cf\u3010\u7531\u591a\u4e2a\u7ebf\u7a0b\u5757\u7ec4\u6210\u7684\u3011\n__global__ void gpu_shared_matrix_transpose(int in[N][M], int out[M][N])\n{\n\n    int y = threadIdx.y + blockDim.y * blockIdx.y;\n    int x = threadIdx.x + blockDim.x * blockIdx.x;\n\n    __shared__ int ken[BLOCK_SIZE+1][BLOCK_SIZE+1];//ken[32] warp\n\n    // step1\uff1a\n    if(x < M && y < N)\n    {   \n        // step1\uff1a\u8bfb\u5230\u5171\u4eab\u5185\u5b58\n        ken[threadIdx.y][threadIdx.x] = in[y][x];\n    }\n    __syncthreads();\n\n    // \u539f\u5219\uff1a\u76f8\u90bb\u7684\u7ebf\u7a0b\u8bbf\u95ee\u76f8\u90bb\u7684\u5750\u6807\n\n    // step2\uff1a  \u5757\u53cd\u8f6c\uff0c\u5757\u5185\u5750\u6807\u4e0d\u53d8\n    int x1 = threadIdx.x + blockDim.y * blockIdx.y;\n    int y1 = threadIdx.y + blockDim.x * blockIdx.x;\n    \n    if(x1 < N && y1 < M)\n    {\n    // step3\uff1a\u4ece\u5171\u4eab\u5185\u5b58\u8bfb\u5230\u8f93\u51fa\u6570\u636e\n        out[y1][x1] = ken[threadIdx.x][threadIdx.y];//32 bank\n    }\n\n}\n\nvoid cpu_matrix_transpose(int in[N][M], int out[M][N])\n{\n    for(int y = 0; y < N; y++)\n    {\n        for(int x = 0; x < M; x++)\n        {\n            out[x][y] = in[y][x];\n        }\n    }\n}\n\nint main()\n{\n    for(int y=0; y<N; y++)\n    {\n        for(int x=0; x<M; x++)\n        {\n            matrix[y][x] = rand()%1024;\n        }\n    }\n\n    cudaEvent_t start, stop_gpu, stop_cpu;\n    cudaEventCreate(&start);\n    cudaEventCreate(&stop_cpu);\n    cudaEventCreate(&stop_gpu);\n\n    cudaEventRecord(start);\n    cudaEventSynchronize(start);\n\n    dim3 dimGrid((M + BLOCK_SIZE - 1)/BLOCK_SIZE, (N + BLOCK_SIZE -1)/BLOCK_SIZE);\n    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n\n    for(int i = 0; i < 20; i++)\n    {\n        // gpu_matrix_transpose<<<dimGrid,dimBlock>>>(matrix, gpu_result);\n        gpu_shared_matrix_transpose<<<dimGrid,dimBlock>>>(matrix, gpu_result);\n        cudaDeviceSynchronize();\n    }\n\n    cudaEventRecord(stop_gpu);\n    cudaEventSynchronize(stop_gpu);\n\n    cpu_matrix_transpose(matrix, cpu_result);\n\n    cudaEventRecord(stop_cpu);\n    cudaEventSynchronize(stop_cpu);\n\n    float time_cpu, time_gpu;\n    cudaEventElapsedTime(&time_gpu, start, stop_gpu);\n    cudaEventElapsedTime(&time_cpu, stop_gpu, stop_cpu);\n\n    bool errors = false;\n    for(int y = 0; y<M; y++)\n    {\n        for (int x = 0; x < N; x++)\n        {\n            if(fabs(cpu_result[y][x] - gpu_result[y][x]) > (1.0e-10))\n            {\n                errors = true;\n            }\n        }\n        \n    }\n\n    printf('Result: %s\\n', errors?'Error':'Pass');\n    printf('CPU time: %.2f\\nGPU time: %.2f\\n', time_cpu, time_gpu/20.0);\n\n    return 0;\n}\n```\u3002", "top": 0, "createdAt": 1769331434, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2026-01-25", "dateLabelColor": "#1f883d"}, "P2": {"htmlDir": "docs/post/\u3010vllm\u3011 -xian-shang-mo-shi.html", "labels": ["documentation"], "postTitle": "\u3010vllm\u3011 \u7ebf\u4e0a\u6a21\u5f0f", "postUrl": "post/%E3%80%90vllm%E3%80%91%20-xian-shang-mo-shi.html", "postSourceUrl": "https://github.com/xx2565/Inkwell/issues/2", "commentNum": 0, "wordCount": 1354, "description": "# APIserver\u5728\u6846\u67b6\u4e2d\u7684\u4f5c\u7528\n## \u8c03\u7528\u94fe\u8def\nvLLM\u7684online serving\u91c7\u7528\u5206\u5c42\u67b6\u6784\uff0c\u4eceHTTP\u63a5\u53e3\u5230\u6838\u5fc3\u63a8\u7406\u5f15\u64ce\u7684\u5b8c\u6574\u94fe\u8def\u5982\u4e0b\uff1a\n\n\u5ba2\u6237\u7aef\u8bf7\u6c42 \u2192 HTTP\u670d\u52a1\u5668 \u2192 API\u8def\u7531 \u2192 \u670d\u52a1\u5c42 \u2192 \u5f15\u64ce\u5ba2\u6237\u7aef \u2192 \u6838\u5fc3\u5f15\u64ce \u2192 \u63a8\u7406\u6267\u884c\n\n\u5177\u4f53\u6587\u4ef6\u94fe\u8def\uff1a\nexamples/online_serving/openai_chat_completion_client.py (\u5ba2\u6237\u7aef)\n    \u2193\nvllm/entrypoints/openai/api_server.py (HTTP\u670d\u52a1\u5668\u5165\u53e3)          \u538b\u6d4b\u5176\u670d\u52a1\u7684\u6587\u4ef6\u5730\u5740\n    \u2193  \nvllm/entrypoints/openai/chat_completion/api_router.py (API\u8def\u7531)\n    \u2193\nvllm/entrypoints/openai/chat_completion/serving.py (\u670d\u52a1\u5c42)\n    \u2193\nvllm/v1/engine/async_llm.py (\u5f02\u6b65\u5f15\u64ce\u5ba2\u6237\u7aef)\n    \u2193\nvllm/v1/engine/core_client.py (\u5f15\u64ce\u6838\u5fc3\u5ba2\u6237\u7aef)\n    \u2193\nvllm/v1/engine/core.py (\u6838\u5fc3\u5f15\u64ce)\n    \u2193\nvllm/v1/executor/ (\u63a8\u7406\u6267\u884c\u5668)\n\n\n\u5ba2\u6237\u7aef (examples/online_serving/openai_chat_completion_client.py)\n    \u2193 HTTP\u8bf7\u6c42\u5230 http://localhost:8000/v1/chat/completions\n\u670d\u52a1\u5668 (vllm/entrypoints/openai/api_server.py)\n    \u2193 \u8def\u7531\u5230 vllm/entrypoints/openai/chat_completion/api_router.py\n    \u2193 \u8c03\u7528 vllm/entrypoints/openai/chat_completion/serving.py\n    \u2193 \u59d4\u6258\u7ed9 vllm/v1/engine/async_llm.py\n\n## \u670d\u52a1\u6a21\u5f0f\u548c\u7a0b\u5e8f\u6a21\u5f0f\u7684\u533a\u522b\uff1a\n\u573a\u666f 1\uff1a\u524d\u7aef\u7f51\u9875\u8981\u7528\u6a21\u578b\ud83d\udc49 \u90a3\u53ea\u80fd\u8d70 HTTP  \n\u573a\u666f 2\uff1a\u5f88\u591a\u4eba\u540c\u65f6\u7528\u6a21\u578b\ud83d\udc49 \u6a21\u578b\u5fc5\u987b\u53ea\u52a0\u8f7d\u4e00\u6b21  \n\u573a\u666f 3\uff1a\u6a21\u578b\u8981\u4e00\u76f4\u5f00\u7740\uff087\u00d724\uff09\ud83d\udc49 \u4e0d\u9002\u5408\u505a\u670d\u52a1  \nAPI Server \u5c31\u662f\u4e3a\u4e86\u89e3\u51b3\u4e0a\u9762\u8fd9\u4e9b\u95ee\u9898  \n\n## \u4ec0\u4e48\u662f FastAPI\uff1f\n\u5982\u679c\u6ca1\u6709 FastAPI\uff0c\u4f60\u8981\u624b\u5199\u5f88\u591a\u9ebb\u70e6\u7684\u4e1c\u897f\uff1a\n\u89e3\u6790 HTTP\n\u89e3\u6790 JSON\n\u6821\u9a8c\u53c2\u6570\n\u8fd4\u56de\u7ed3\u679c\nFastAPI \u5e2e\u4f60\u5168\u505a\u4e86\u3002", "top": 0, "createdAt": 1770365507, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2026-02-06", "dateLabelColor": "#1f883d"}}, "singeListJson": {}, "labelColorDict": {"bug": "#d73a4a", "documentation": "#0075ca", "duplicate": "#cfd3d7", "enhancement": "#a2eeef", "good first issue": "#7057ff", "help wanted": "#008672", "invalid": "#e4e669", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "Blog Title", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "homeUrl": "https://xx2565.github.io/Inkwell", "prevUrl": "disabled", "nextUrl": "disabled"}