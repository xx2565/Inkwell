# APIserveråœ¨æ¡†æ¶ä¸­çš„ä½œç”¨
## è°ƒç”¨é“¾è·¯
vLLMçš„online servingé‡‡ç”¨åˆ†å±‚æ¶æ„ï¼Œä»HTTPæ¥å£åˆ°æ ¸å¿ƒæ¨ç†å¼•æ“çš„å®Œæ•´é“¾è·¯å¦‚ä¸‹ï¼š

å®¢æˆ·ç«¯è¯·æ±‚ â†’ HTTPæœåŠ¡å™¨ â†’ APIè·¯ç”± â†’ æœåŠ¡å±‚ â†’ å¼•æ“å®¢æˆ·ç«¯ â†’ æ ¸å¿ƒå¼•æ“ â†’ æ¨ç†æ‰§è¡Œ

å…·ä½“æ–‡ä»¶é“¾è·¯ï¼š
examples/online_serving/openai_chat_completion_client.py (å®¢æˆ·ç«¯)
    â†“
vllm/entrypoints/openai/api_server.py (HTTPæœåŠ¡å™¨å…¥å£)          å‹æµ‹å…¶æœåŠ¡çš„æ–‡ä»¶åœ°å€
    â†“  
vllm/entrypoints/openai/chat_completion/api_router.py (APIè·¯ç”±)
    â†“
vllm/entrypoints/openai/chat_completion/serving.py (æœåŠ¡å±‚)
    â†“
vllm/v1/engine/async_llm.py (å¼‚æ­¥å¼•æ“å®¢æˆ·ç«¯)
    â†“
vllm/v1/engine/core_client.py (å¼•æ“æ ¸å¿ƒå®¢æˆ·ç«¯)
    â†“
vllm/v1/engine/core.py (æ ¸å¿ƒå¼•æ“)
    â†“
vllm/v1/executor/ (æ¨ç†æ‰§è¡Œå™¨)


å®¢æˆ·ç«¯ (examples/online_serving/openai_chat_completion_client.py)
    â†“ HTTPè¯·æ±‚åˆ° http://localhost:8000/v1/chat/completions
æœåŠ¡å™¨ (vllm/entrypoints/openai/api_server.py)
    â†“ è·¯ç”±åˆ° vllm/entrypoints/openai/chat_completion/api_router.py
    â†“ è°ƒç”¨ vllm/entrypoints/openai/chat_completion/serving.py
    â†“ å§”æ‰˜ç»™ vllm/v1/engine/async_llm.py

## æœåŠ¡æ¨¡å¼å’Œç¨‹åºæ¨¡å¼çš„åŒºåˆ«ï¼š
åœºæ™¯ 1ï¼šå‰ç«¯ç½‘é¡µè¦ç”¨æ¨¡å‹ğŸ‘‰ é‚£åªèƒ½èµ° HTTP  
åœºæ™¯ 2ï¼šå¾ˆå¤šäººåŒæ—¶ç”¨æ¨¡å‹ğŸ‘‰ æ¨¡å‹å¿…é¡»åªåŠ è½½ä¸€æ¬¡  
åœºæ™¯ 3ï¼šæ¨¡å‹è¦ä¸€ç›´å¼€ç€ï¼ˆ7Ã—24ï¼‰ğŸ‘‰ ä¸é€‚åˆåšæœåŠ¡  
API Server å°±æ˜¯ä¸ºäº†è§£å†³ä¸Šé¢è¿™äº›é—®é¢˜  

## ä»€ä¹ˆæ˜¯ FastAPIï¼Ÿ
å¦‚æœæ²¡æœ‰ FastAPIï¼Œä½ è¦æ‰‹å†™å¾ˆå¤šéº»çƒ¦çš„ä¸œè¥¿ï¼š
è§£æ HTTP
è§£æ JSON
æ ¡éªŒå‚æ•°
è¿”å›ç»“æœ
FastAPI å¸®ä½ å…¨åšäº†ã€‚

```python 
from fastapi import FastAPI

app = FastAPI()

@app.post("/hello")
def hello(req: dict):
    return {"reply": "Hello " + req["name"]}```

uvicorn         # è´Ÿè´£ç›‘å¬ç«¯å£
  â””â”€ FastAPI app
      â””â”€ /v1/completions
          â””â”€ è°ƒç”¨ vLLM Engine`



